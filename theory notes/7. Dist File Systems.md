# GFS
Files:
- Divided into fixed size chunks
- Chunks are stored at chunk server
- Replicated in chunk servers
- Masters keep track of metadata
	- Which chunk belong to which server?

These chunks are replicated on various chunk servers. The chunk servers themselves are not complete replicas of other servers

## Basic Operations

- Client retrieves file metadata from master
- Read/write file data is communicated between client and the chunk server
- Minimize the communication with master for read/write operations
	- Metadata caching
- Chunk Handle is a 64 bit unique global identifier
### GFS Write
1. (filename, byte range, data) Application -> GFS client
	- client breaks up the byte range by chunk size and gets chunk index
2. (filename, chunk index) GFS Client -> Master
	- Master assigns a chunk, gives a chunk handle and where chunks and its replicas are located
3. (chunk handle, Primary, secondary replica location) Master -> Client
	- GFS client sends data to primary, who orders the writes w1, w2, w3 ( not yet written to chunk)
4. (data, byte ranges) Client -> Primary
5. (write command) Client -> Primary
6. Primary dictates secondary to make updates in the same order
7. Primary waits for response received from secondary chunk servers
8. Write completes when primary responds to GFS client

Addendum:
- GFS doesnt copy to all chunk replicas, just 3
- GFS save bandwidth by chaining from primary to secondary
- All chunk replicas have the same content, 2 different chunks can have differently ordered writes. (slide 15/30 DFS2)

What happens with multiple write operations to the same chunk?
- GFS does not provide any guarantee
- Chunk may end up having mixed updates from clients
- Requires extensive locks and synchronization at application layer to avoid such issues

### Record Append
- Atomic Append Operation
- Client specifies only the data, but not the offset where the data to be written
- Used heavily by distributed applications
- "i just want it to be in there stream"

1. (filename, data) Application -> GFS client
2. (filename, last chunk) GFS Client, Master
	- client asks master about the last chunk of the file
3. (chunk handle, Primary, secondary replica location) Master -> Client
	- GFS client sends data to primary, who orders the writes w1, w2, w3 ( not yet written to chunk)
4. (Push Data) Client -> Primary and or Secondaries
	1. Primary dictates secondary to make updates in the same order
	2. Primary waits for response received from secondary chunk servers
5. Primary does not find enough space in the chunk, pads the chunk, secondary do the same
6. Send failure to client and asks to retry it on next chunk
7. Primary does find enough space in the chunk, copies in its replica and ask all secondary to do so.
8. Write completes when primary responds to GFS client

If a replica fails to copy the GFS **client** will retry the operation. This might result in duplicates to some replicas.

### Dealing with inconsistencies
- Use checksum for writing every file record
	- The checksum can be used to correct and detect inconsistencies in writing

- Use unique id for a file record to identify duplicates
- All these happen in the application layer